{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83bc521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import interpolate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a459a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_q1(df, split_col, filter_col=\"Score\"):\n",
    "    return df.groupby(split_col).apply(lambda x: x[x[filter_col] <= x[filter_col].quantile(0.25)]).reset_index(drop=True)\n",
    "def filter_q3(df, split_col, filter_col=\"Score\"):\n",
    "    return df.groupby(split_col).apply(lambda x: x[x[filter_col] >= x[filter_col].quantile(0.75)]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2208ae5",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94e77241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_depth_rel_all = pd.read_csv(\"data/depth/rel_depth_statistics_combined.csv\") \n",
    "#df_depth_abs_all = pd.read_csv(\"data/depth/met_depth_statistics_combined.csv\") \n",
    "\n",
    "df_singleSVI_multiPar = pd.read_csv(\"data/labels/processed/singleSVI_multiPar_qscores.csv\")\n",
    "df_multiSVI_singlePar = pd.read_csv(\"data/labels/processed/multiSVI_singlePar_qscores.csv\")\n",
    "\n",
    "df_metadata = pd.read_csv(\"data/svi/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135cd609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>depth</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dc6eee81-9513-4edb-813b-05b83b5127be</td>\n",
       "      <td>[30.194952, 30.022743, 29.850534, 29.795359, 2...</td>\n",
       "      <td>41.001743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50811b7a-5b0f-4581-92fa-017e6ff26ba0</td>\n",
       "      <td>[22.900692, 22.54313, 22.185568, 21.76648, 21....</td>\n",
       "      <td>34.022415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35c8af9e-5e36-4810-9824-59b9b273fbcf</td>\n",
       "      <td>[21.422682, 21.04729, 20.671898, 20.382578, 20...</td>\n",
       "      <td>31.951784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3a439403-305b-4be7-ba43-f8ff8e75c31c</td>\n",
       "      <td>[21.728897, 21.46422, 21.199545, 20.82807, 20....</td>\n",
       "      <td>30.652710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3cc24150-c590-4d83-883c-44855010e338</td>\n",
       "      <td>[28.704128, 28.510593, 28.317057, 28.211706, 2...</td>\n",
       "      <td>28.679663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>416a4869-428a-475a-92bd-19f2611b2925</td>\n",
       "      <td>[36.988827, 36.921658, 36.85449, 36.78854, 36....</td>\n",
       "      <td>30.508865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>dad8c5a5-80cd-4d1e-a3cc-b429cdbb90c2</td>\n",
       "      <td>[44.055176, 44.45355, 44.851925, 45.250237, 45...</td>\n",
       "      <td>30.887470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>b7abb7f7-7031-4fc9-8f16-7e591dcdfbce</td>\n",
       "      <td>[36.21824, 36.416855, 36.615475, 36.81323, 36....</td>\n",
       "      <td>41.819267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>41a8b6ce-02df-47e8-b7d1-10cce55b6575</td>\n",
       "      <td>[25.324125, 25.195616, 25.06711, 24.939291, 24...</td>\n",
       "      <td>23.466200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>e97e0042-0ca3-47a2-a514-7422cb60e6a6</td>\n",
       "      <td>[13.757727, 13.472207, 13.186688, 12.903467, 1...</td>\n",
       "      <td>37.337883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     uuid  \\\n",
       "0    dc6eee81-9513-4edb-813b-05b83b5127be   \n",
       "1    50811b7a-5b0f-4581-92fa-017e6ff26ba0   \n",
       "2    35c8af9e-5e36-4810-9824-59b9b273fbcf   \n",
       "3    3a439403-305b-4be7-ba43-f8ff8e75c31c   \n",
       "4    3cc24150-c590-4d83-883c-44855010e338   \n",
       "..                                    ...   \n",
       "395  416a4869-428a-475a-92bd-19f2611b2925   \n",
       "396  dad8c5a5-80cd-4d1e-a3cc-b429cdbb90c2   \n",
       "397  b7abb7f7-7031-4fc9-8f16-7e591dcdfbce   \n",
       "398  41a8b6ce-02df-47e8-b7d1-10cce55b6575   \n",
       "399  e97e0042-0ca3-47a2-a514-7422cb60e6a6   \n",
       "\n",
       "                                                 depth     median  \n",
       "0    [30.194952, 30.022743, 29.850534, 29.795359, 2...  41.001743  \n",
       "1    [22.900692, 22.54313, 22.185568, 21.76648, 21....  34.022415  \n",
       "2    [21.422682, 21.04729, 20.671898, 20.382578, 20...  31.951784  \n",
       "3    [21.728897, 21.46422, 21.199545, 20.82807, 20....  30.652710  \n",
       "4    [28.704128, 28.510593, 28.317057, 28.211706, 2...  28.679663  \n",
       "..                                                 ...        ...  \n",
       "395  [36.988827, 36.921658, 36.85449, 36.78854, 36....  30.508865  \n",
       "396  [44.055176, 44.45355, 44.851925, 45.250237, 45...  30.887470  \n",
       "397  [36.21824, 36.416855, 36.615475, 36.81323, 36....  41.819267  \n",
       "398  [25.324125, 25.195616, 25.06711, 24.939291, 24...  23.466200  \n",
       "399  [13.757727, 13.472207, 13.186688, 12.903467, 1...  37.337883  \n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load each SVI depth calculations (in meters)\n",
    "list_ids = df_metadata[\"uuid\"]\n",
    "\n",
    "depth_data = []\n",
    "\n",
    "for uuid in list_ids:\n",
    "    depth_val = np.load(f\"data/depth/met_depth/{uuid}_depth.npy\")\n",
    "    depth_data.append({'uuid': uuid, 'depth': depth_val[0]})\n",
    "df_depth_rel = pd.DataFrame(depth_data)\n",
    "df_depth_rel['median'] = df_depth_rel['depth'].apply(np.median)\n",
    "df_depth_rel # depth npy values for all svis that will be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f2ba5",
   "metadata": {},
   "source": [
    "# Filtering only green answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4a5c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_singleSVI_multiPar = df_singleSVI_multiPar[df_singleSVI_multiPar[\"Question\"] == \"green\"]\n",
    "df_multiSVI_singlePar = df_multiSVI_singlePar[df_multiSVI_singlePar[\"Question\"] == \"green\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a0d30",
   "metadata": {},
   "source": [
    "# Divide into Q1 and Q3 quantiles based on perception Q scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be333c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kw/9lnn_1r159n28p1krywmf8_w0000gq/T/ipykernel_37036/3541013002.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(split_col).apply(lambda x: x[x[filter_col] <= x[filter_col].quantile(0.25)]).reset_index(drop=True)\n",
      "/var/folders/kw/9lnn_1r159n28p1krywmf8_w0000gq/T/ipykernel_37036/3541013002.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(split_col).apply(lambda x: x[x[filter_col] >= x[filter_col].quantile(0.75)]).reset_index(drop=True)\n",
      "/var/folders/kw/9lnn_1r159n28p1krywmf8_w0000gq/T/ipykernel_37036/3541013002.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(split_col).apply(lambda x: x[x[filter_col] <= x[filter_col].quantile(0.25)]).reset_index(drop=True)\n",
      "/var/folders/kw/9lnn_1r159n28p1krywmf8_w0000gq/T/ipykernel_37036/3541013002.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(split_col).apply(lambda x: x[x[filter_col] >= x[filter_col].quantile(0.75)]).reset_index(drop=True)\n",
      "/var/folders/kw/9lnn_1r159n28p1krywmf8_w0000gq/T/ipykernel_37036/3541013002.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(split_col).apply(lambda x: x[x[filter_col] <= x[filter_col].quantile(0.25)]).reset_index(drop=True)\n",
      "/var/folders/kw/9lnn_1r159n28p1krywmf8_w0000gq/T/ipykernel_37036/3541013002.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(split_col).apply(lambda x: x[x[filter_col] >= x[filter_col].quantile(0.75)]).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# single SVI multi participant ratings\n",
    "df_single_q1 = filter_q1(df_singleSVI_multiPar, \"SVI_from\")\n",
    "df_single_q1['quantile'] = \"Q1\"\n",
    "df_single_q3 = filter_q3(df_singleSVI_multiPar, \"SVI_from\")\n",
    "df_single_q3['quantile'] = \"Q3\"\n",
    "df_single_depth_q1q3 = pd.concat([df_single_q1, df_single_q3])\n",
    "\n",
    "# multi SVI single participant ratings\n",
    "df_multi_q1 = filter_q1(df_multiSVI_singlePar, \"participants_from\")\n",
    "df_multi_q1['quantile'] = \"Q1\"\n",
    "df_multi_q3 = filter_q3(df_multiSVI_singlePar, \"participants_from\")\n",
    "df_multi_q3['quantile'] = \"Q3\"\n",
    "df_multi_depth_q1q3 = pd.concat([df_multi_q1, df_multi_q3])\n",
    "\n",
    "# location pair ratings (svi from and participants from)\n",
    "df_par_from_svi_from = df_multiSVI_singlePar.merge(\n",
    "    df_metadata[['Image number', 'city']].rename(columns={'city': 'SVI_from'}),\n",
    "    left_on='Image',\n",
    "    right_on='Image number',\n",
    "    how='left'\n",
    ")\n",
    "df_par_from_svi_from = df_par_from_svi_from[df_par_from_svi_from['participants_from'] != 'All']\n",
    "df_par_from_svi_from_q1 = filter_q1(df_par_from_svi_from, [\"SVI_from\", \"participants_from\"])\n",
    "df_par_from_svi_from_q1['quantile'] = \"Q1\"\n",
    "df_par_from_svi_from_q3 = filter_q3(df_par_from_svi_from, [\"SVI_from\", \"participants_from\"])\n",
    "df_par_from_svi_from_q3['quantile'] = \"Q3\"\n",
    "df_par_from_svi_from_q1q3 = pd.concat([df_par_from_svi_from_q1, df_par_from_svi_from_q3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "406890db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVI_from       quantile\n",
      "Abuja          Q1           20\n",
      "               Q3           20\n",
      "All            Q1          100\n",
      "               Q3          100\n",
      "Amsterdam      Q1           20\n",
      "               Q3           20\n",
      "San Francisco  Q1           20\n",
      "               Q3           20\n",
      "Santiago       Q1           20\n",
      "               Q3           20\n",
      "Singapore      Q1           20\n",
      "               Q3           20\n",
      "dtype: int64\n",
      "20\n",
      "\n",
      "\n",
      "participants_from  quantile\n",
      "All                Q1          100\n",
      "                   Q3          100\n",
      "Chile              Q1           76\n",
      "                   Q3           77\n",
      "Netherlands        Q1           77\n",
      "                   Q3           77\n",
      "Nigeria            Q1           80\n",
      "                   Q3           77\n",
      "Singapore          Q1           78\n",
      "                   Q3           75\n",
      "USA                Q1           75\n",
      "                   Q3           75\n",
      "dtype: int64\n",
      "75\n",
      "\n",
      "\n",
      "SVI_from       participants_from  quantile\n",
      "Abuja          Chile              Q1          15\n",
      "                                  Q3          15\n",
      "               Netherlands        Q1          15\n",
      "                                  Q3          15\n",
      "               Nigeria            Q1          15\n",
      "                                  Q3          15\n",
      "               Singapore          Q1          17\n",
      "                                  Q3          17\n",
      "               USA                Q1          15\n",
      "                                  Q3          15\n",
      "Amsterdam      Chile              Q1          16\n",
      "                                  Q3          16\n",
      "               Netherlands        Q1          14\n",
      "                                  Q3          14\n",
      "               Nigeria            Q1          16\n",
      "                                  Q3          16\n",
      "               Singapore          Q1          15\n",
      "                                  Q3          15\n",
      "               USA                Q1          16\n",
      "                                  Q3          15\n",
      "San Francisco  Chile              Q1          15\n",
      "                                  Q3          15\n",
      "               Netherlands        Q1          16\n",
      "                                  Q3          16\n",
      "               Nigeria            Q1          15\n",
      "                                  Q3          16\n",
      "               Singapore          Q1          15\n",
      "                                  Q3          15\n",
      "               USA                Q1          16\n",
      "                                  Q3          16\n",
      "Santiago       Chile              Q1          17\n",
      "                                  Q3          17\n",
      "               Netherlands        Q1          17\n",
      "                                  Q3          17\n",
      "               Nigeria            Q1          15\n",
      "                                  Q3          15\n",
      "               Singapore          Q1          15\n",
      "                                  Q3          15\n",
      "               USA                Q1          15\n",
      "                                  Q3          15\n",
      "Singapore      Chile              Q1          14\n",
      "                                  Q3          14\n",
      "               Netherlands        Q1          16\n",
      "                                  Q3          16\n",
      "               Nigeria            Q1          15\n",
      "                                  Q3          15\n",
      "               Singapore          Q1          16\n",
      "                                  Q3          16\n",
      "               USA                Q1          17\n",
      "                                  Q3          16\n",
      "dtype: int64\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(df_single_depth_q1q3.groupby([\"SVI_from\", \"quantile\"]).size()) # n >= 20\n",
    "print(df_single_depth_q1q3.groupby([\"SVI_from\", \"quantile\"]).size().min())\n",
    "print(\"\\n\")\n",
    "print(df_multi_depth_q1q3.groupby([\"participants_from\", \"quantile\"]).size()) # n >= 30\n",
    "print(df_multi_depth_q1q3.groupby([\"participants_from\", \"quantile\"]).size().min())\n",
    "print(\"\\n\")\n",
    "print(df_par_from_svi_from_q1q3.groupby([\"SVI_from\", \"participants_from\", \"quantile\"]).size()) # n >= 14\n",
    "print(df_par_from_svi_from_q1q3.groupby([\"SVI_from\", \"participants_from\", \"quantile\"]).size().min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827ebcff",
   "metadata": {},
   "source": [
    "# Divide into Q1 and Q3 quantiles based on depth median "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9736d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_singleSVI_multiPar = df_singleSVI_multiPar.merge(df_depth_rel, on=\"uuid\")\n",
    "df_multiSVI_singlePar = df_multiSVI_singlePar.merge(df_depth_rel, on=\"uuid\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2f48d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kw/9lnn_1r159n28p1krywmf8_w0000gq/T/ipykernel_37036/3541013002.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(split_col).apply(lambda x: x[x[filter_col] <= x[filter_col].quantile(0.25)]).reset_index(drop=True)\n",
      "/var/folders/kw/9lnn_1r159n28p1krywmf8_w0000gq/T/ipykernel_37036/3541013002.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(split_col).apply(lambda x: x[x[filter_col] >= x[filter_col].quantile(0.75)]).reset_index(drop=True)\n",
      "/var/folders/kw/9lnn_1r159n28p1krywmf8_w0000gq/T/ipykernel_37036/3541013002.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(split_col).apply(lambda x: x[x[filter_col] <= x[filter_col].quantile(0.25)]).reset_index(drop=True)\n",
      "/var/folders/kw/9lnn_1r159n28p1krywmf8_w0000gq/T/ipykernel_37036/3541013002.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(split_col).apply(lambda x: x[x[filter_col] >= x[filter_col].quantile(0.75)]).reset_index(drop=True)\n",
      "/var/folders/kw/9lnn_1r159n28p1krywmf8_w0000gq/T/ipykernel_37036/3541013002.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(split_col).apply(lambda x: x[x[filter_col] <= x[filter_col].quantile(0.25)]).reset_index(drop=True)\n",
      "/var/folders/kw/9lnn_1r159n28p1krywmf8_w0000gq/T/ipykernel_37036/3541013002.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return df.groupby(split_col).apply(lambda x: x[x[filter_col] >= x[filter_col].quantile(0.75)]).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# single SVI multi participant ratings\n",
    "df_single_median_q1 = filter_q1(df_singleSVI_multiPar, \"SVI_from\", \"median\")\n",
    "df_single_median_q1['quantile'] = \"Q1\"\n",
    "df_single_median_q3 = filter_q3(df_singleSVI_multiPar, \"SVI_from\", \"median\")\n",
    "df_single_median_q3['quantile'] = \"Q3\"\n",
    "df_single_median_depth_q1q3 = pd.concat([df_single_median_q1, df_single_median_q3])\n",
    "\n",
    "# multi SVI single participant ratings\n",
    "df_multi_median_q1 = filter_q1(df_multiSVI_singlePar, \"participants_from\", \"median\")\n",
    "df_multi_median_q1['quantile'] = \"Q1\"\n",
    "df_multi_median_q3 = filter_q3(df_multiSVI_singlePar, \"participants_from\", \"median\")\n",
    "df_multi_median_q3['quantile'] = \"Q3\"\n",
    "df_multi_median_depth_q1q3 = pd.concat([df_multi_median_q1, df_multi_median_q3])\n",
    "\n",
    "# location pair ratings (svi from and participants from)\n",
    "df_par_from_svi_from_median = df_multiSVI_singlePar.merge(\n",
    "    df_metadata[['Image number', 'city']].rename(columns={'city': 'SVI_from'}),\n",
    "    left_on='Image',\n",
    "    right_on='Image number',\n",
    "    how='left'\n",
    ")\n",
    "df_par_from_svi_from_median = df_par_from_svi_from_median[df_par_from_svi_from_median['participants_from'] != 'All']\n",
    "df_par_from_svi_from_median_q1 = filter_q1(df_par_from_svi_from_median, [\"SVI_from\", \"participants_from\"], \"median\")\n",
    "df_par_from_svi_from_median_q1['quantile'] = \"Q1\"\n",
    "df_par_from_svi_from_median_q3 = filter_q3(df_par_from_svi_from_median, [\"SVI_from\", \"participants_from\"], \"median\")\n",
    "df_par_from_svi_from_median_q3['quantile'] = \"Q3\"\n",
    "df_par_from_svi_from_median_q1q3 = pd.concat([df_par_from_svi_from_median_q1, df_par_from_svi_from_median_q3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "734be61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVI_from       quantile\n",
      "Abuja          Q1           20\n",
      "               Q3           20\n",
      "All            Q1          100\n",
      "               Q3          100\n",
      "Amsterdam      Q1           20\n",
      "               Q3           20\n",
      "San Francisco  Q1           20\n",
      "               Q3           20\n",
      "Santiago       Q1           20\n",
      "               Q3           20\n",
      "Singapore      Q1           20\n",
      "               Q3           20\n",
      "dtype: int64\n",
      "20\n",
      "\n",
      "\n",
      "participants_from  quantile\n",
      "All                Q1          100\n",
      "                   Q3          100\n",
      "Chile              Q1           76\n",
      "                   Q3           76\n",
      "Netherlands        Q1           77\n",
      "                   Q3           77\n",
      "Nigeria            Q1           75\n",
      "                   Q3           75\n",
      "Singapore          Q1           75\n",
      "                   Q3           75\n",
      "USA                Q1           75\n",
      "                   Q3           75\n",
      "dtype: int64\n",
      "75\n",
      "\n",
      "\n",
      "SVI_from       participants_from  quantile\n",
      "Abuja          Chile              Q1          15\n",
      "                                  Q3          15\n",
      "               Netherlands        Q1          15\n",
      "                                  Q3          15\n",
      "               Nigeria            Q1          15\n",
      "                                  Q3          15\n",
      "               Singapore          Q1          16\n",
      "                                  Q3          16\n",
      "               USA                Q1          15\n",
      "                                  Q3          15\n",
      "Amsterdam      Chile              Q1          16\n",
      "                                  Q3          16\n",
      "               Netherlands        Q1          14\n",
      "                                  Q3          14\n",
      "               Nigeria            Q1          16\n",
      "                                  Q3          16\n",
      "               Singapore          Q1          15\n",
      "                                  Q3          15\n",
      "               USA                Q1          15\n",
      "                                  Q3          15\n",
      "San Francisco  Chile              Q1          15\n",
      "                                  Q3          15\n",
      "               Netherlands        Q1          16\n",
      "                                  Q3          16\n",
      "               Nigeria            Q1          15\n",
      "                                  Q3          15\n",
      "               Singapore          Q1          15\n",
      "                                  Q3          15\n",
      "               USA                Q1          16\n",
      "                                  Q3          16\n",
      "Santiago       Chile              Q1          17\n",
      "                                  Q3          17\n",
      "               Netherlands        Q1          17\n",
      "                                  Q3          17\n",
      "               Nigeria            Q1          15\n",
      "                                  Q3          15\n",
      "               Singapore          Q1          15\n",
      "                                  Q3          15\n",
      "               USA                Q1          15\n",
      "                                  Q3          15\n",
      "Singapore      Chile              Q1          14\n",
      "                                  Q3          14\n",
      "               Netherlands        Q1          16\n",
      "                                  Q3          16\n",
      "               Nigeria            Q1          15\n",
      "                                  Q3          15\n",
      "               Singapore          Q1          16\n",
      "                                  Q3          16\n",
      "               USA                Q1          16\n",
      "                                  Q3          16\n",
      "dtype: int64\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(df_single_median_depth_q1q3.groupby([\"SVI_from\", \"quantile\"]).size()) # n >= 20\n",
    "print(df_single_median_depth_q1q3.groupby([\"SVI_from\", \"quantile\"]).size().min())\n",
    "print(\"\\n\")\n",
    "print(df_multi_median_depth_q1q3.groupby([\"participants_from\", \"quantile\"]).size()) # n >= 30\n",
    "print(df_multi_median_depth_q1q3.groupby([\"participants_from\", \"quantile\"]).size().min())\n",
    "print(\"\\n\")\n",
    "print(df_par_from_svi_from_median_q1q3.groupby([\"SVI_from\", \"participants_from\", \"quantile\"]).size()) # n >= 14\n",
    "print(df_par_from_svi_from_median_q1q3.groupby([\"SVI_from\", \"participants_from\", \"quantile\"]).size().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919a8bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Question</th>\n",
       "      <th>Score</th>\n",
       "      <th>Num_comparisons</th>\n",
       "      <th>uuid</th>\n",
       "      <th>city</th>\n",
       "      <th>Relabelled Name</th>\n",
       "      <th>Image number</th>\n",
       "      <th>green_view_index</th>\n",
       "      <th>SVI_from</th>\n",
       "      <th>depth</th>\n",
       "      <th>median</th>\n",
       "      <th>quantile</th>\n",
       "      <th>grouping</th>\n",
       "      <th>participants_from</th>\n",
       "      <th>Image number_x</th>\n",
       "      <th>Image number_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>green</td>\n",
       "      <td>6.517522</td>\n",
       "      <td>21</td>\n",
       "      <td>8e0aad6e-670c-4650-b4d3-6adc3c7da26c</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>Image_119</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.274513</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>[22.074812, 21.85407, 21.633331, 21.414415, 21...</td>\n",
       "      <td>27.724718</td>\n",
       "      <td>Q1</td>\n",
       "      <td>SVI_from</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>green</td>\n",
       "      <td>4.585353</td>\n",
       "      <td>21</td>\n",
       "      <td>7e4701f6-fbe6-4c8a-b847-2468d6a4978d</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>Image_154</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.350130</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>[15.1424465, 14.793273, 14.444099, 14.097632, ...</td>\n",
       "      <td>15.181726</td>\n",
       "      <td>Q1</td>\n",
       "      <td>SVI_from</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141</td>\n",
       "      <td>green</td>\n",
       "      <td>5.599960</td>\n",
       "      <td>30</td>\n",
       "      <td>eee6dd59-4096-4c8c-ae6a-6dc872b7c187</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>Image_141</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.250742</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>[29.630459, 29.431488, 29.23252, 29.034222, 28...</td>\n",
       "      <td>29.178806</td>\n",
       "      <td>Q1</td>\n",
       "      <td>SVI_from</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>green</td>\n",
       "      <td>3.848047</td>\n",
       "      <td>24</td>\n",
       "      <td>1fa2ab0a-14b4-4d2a-9522-7a8e5e6faa97</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>Image_103</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.042903</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>[26.363457, 26.199791, 26.036125, 25.873568, 2...</td>\n",
       "      <td>30.333471</td>\n",
       "      <td>Q1</td>\n",
       "      <td>SVI_from</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84</td>\n",
       "      <td>green</td>\n",
       "      <td>5.747354</td>\n",
       "      <td>23</td>\n",
       "      <td>c1e12031-ae65-4ad4-93e9-88a3c00cc96f</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>Image_84</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.324266</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>[29.393862, 29.239325, 29.08479, 28.93081, 28....</td>\n",
       "      <td>29.220842</td>\n",
       "      <td>Q1</td>\n",
       "      <td>SVI_from</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>215</td>\n",
       "      <td>green</td>\n",
       "      <td>5.917108</td>\n",
       "      <td>6</td>\n",
       "      <td>a37b8477-4edf-4f49-b36f-2dd10e467f09</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Image_215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>[12.096749, 11.846966, 11.597183, 11.3474, 11....</td>\n",
       "      <td>39.576370</td>\n",
       "      <td>Q3</td>\n",
       "      <td>location_pairs</td>\n",
       "      <td>USA</td>\n",
       "      <td>215.0</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>231</td>\n",
       "      <td>green</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>0a82c461-302e-45e9-afcb-5194bec3e123</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Image_231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.233716</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>[27.620184, 27.597359, 27.574535, 27.552296, 2...</td>\n",
       "      <td>35.584648</td>\n",
       "      <td>Q3</td>\n",
       "      <td>location_pairs</td>\n",
       "      <td>USA</td>\n",
       "      <td>231.0</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>161</td>\n",
       "      <td>green</td>\n",
       "      <td>5.511905</td>\n",
       "      <td>8</td>\n",
       "      <td>a5e78fa1-a4b9-4062-a2f5-e4bd3b5854dd</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Image_161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.236604</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>[22.736694, 22.546032, 22.35537, 22.16471, 22....</td>\n",
       "      <td>38.370567</td>\n",
       "      <td>Q3</td>\n",
       "      <td>location_pairs</td>\n",
       "      <td>USA</td>\n",
       "      <td>161.0</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>219</td>\n",
       "      <td>green</td>\n",
       "      <td>7.685185</td>\n",
       "      <td>6</td>\n",
       "      <td>5446831e-9c5b-4390-a583-6f0f3e3877ca</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Image_219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.251703</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>[13.32514, 12.96369, 12.60224, 12.240788, 12.0...</td>\n",
       "      <td>35.485519</td>\n",
       "      <td>Q3</td>\n",
       "      <td>location_pairs</td>\n",
       "      <td>USA</td>\n",
       "      <td>219.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>191</td>\n",
       "      <td>green</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>0ee82372-34f5-4017-831a-50a93e4b7e69</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Image_191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.082525</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>[36.802605, 36.829563, 36.85652, 36.883484, 36...</td>\n",
       "      <td>37.532478</td>\n",
       "      <td>Q3</td>\n",
       "      <td>location_pairs</td>\n",
       "      <td>USA</td>\n",
       "      <td>191.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2126 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Image Question     Score  Num_comparisons  \\\n",
       "0      119    green  6.517522               21   \n",
       "1      154    green  4.585353               21   \n",
       "2      141    green  5.599960               30   \n",
       "3      103    green  3.848047               24   \n",
       "4       84    green  5.747354               23   \n",
       "..     ...      ...       ...              ...   \n",
       "380    215    green  5.917108                6   \n",
       "381    231    green  4.500000                4   \n",
       "382    161    green  5.511905                8   \n",
       "383    219    green  7.685185                6   \n",
       "384    191    green  4.500000                4   \n",
       "\n",
       "                                     uuid       city Relabelled Name  \\\n",
       "0    8e0aad6e-670c-4650-b4d3-6adc3c7da26c      Abuja       Image_119   \n",
       "1    7e4701f6-fbe6-4c8a-b847-2468d6a4978d      Abuja       Image_154   \n",
       "2    eee6dd59-4096-4c8c-ae6a-6dc872b7c187      Abuja       Image_141   \n",
       "3    1fa2ab0a-14b4-4d2a-9522-7a8e5e6faa97      Abuja       Image_103   \n",
       "4    c1e12031-ae65-4ad4-93e9-88a3c00cc96f      Abuja        Image_84   \n",
       "..                                    ...        ...             ...   \n",
       "380  a37b8477-4edf-4f49-b36f-2dd10e467f09  Singapore       Image_215   \n",
       "381  0a82c461-302e-45e9-afcb-5194bec3e123  Singapore       Image_231   \n",
       "382  a5e78fa1-a4b9-4062-a2f5-e4bd3b5854dd  Singapore       Image_161   \n",
       "383  5446831e-9c5b-4390-a583-6f0f3e3877ca  Singapore       Image_219   \n",
       "384  0ee82372-34f5-4017-831a-50a93e4b7e69  Singapore       Image_191   \n",
       "\n",
       "     Image number  green_view_index   SVI_from  \\\n",
       "0           119.0          0.274513      Abuja   \n",
       "1           154.0          0.350130      Abuja   \n",
       "2           141.0          0.250742      Abuja   \n",
       "3           103.0          0.042903      Abuja   \n",
       "4            84.0          0.324266      Abuja   \n",
       "..            ...               ...        ...   \n",
       "380           NaN          0.233810  Singapore   \n",
       "381           NaN          0.233716  Singapore   \n",
       "382           NaN          0.236604  Singapore   \n",
       "383           NaN          0.251703  Singapore   \n",
       "384           NaN          0.082525  Singapore   \n",
       "\n",
       "                                                 depth     median quantile  \\\n",
       "0    [22.074812, 21.85407, 21.633331, 21.414415, 21...  27.724718       Q1   \n",
       "1    [15.1424465, 14.793273, 14.444099, 14.097632, ...  15.181726       Q1   \n",
       "2    [29.630459, 29.431488, 29.23252, 29.034222, 28...  29.178806       Q1   \n",
       "3    [26.363457, 26.199791, 26.036125, 25.873568, 2...  30.333471       Q1   \n",
       "4    [29.393862, 29.239325, 29.08479, 28.93081, 28....  29.220842       Q1   \n",
       "..                                                 ...        ...      ...   \n",
       "380  [12.096749, 11.846966, 11.597183, 11.3474, 11....  39.576370       Q3   \n",
       "381  [27.620184, 27.597359, 27.574535, 27.552296, 2...  35.584648       Q3   \n",
       "382  [22.736694, 22.546032, 22.35537, 22.16471, 22....  38.370567       Q3   \n",
       "383  [13.32514, 12.96369, 12.60224, 12.240788, 12.0...  35.485519       Q3   \n",
       "384  [36.802605, 36.829563, 36.85652, 36.883484, 36...  37.532478       Q3   \n",
       "\n",
       "           grouping participants_from  Image number_x  Image number_y  \n",
       "0          SVI_from               NaN             NaN             NaN  \n",
       "1          SVI_from               NaN             NaN             NaN  \n",
       "2          SVI_from               NaN             NaN             NaN  \n",
       "3          SVI_from               NaN             NaN             NaN  \n",
       "4          SVI_from               NaN             NaN             NaN  \n",
       "..              ...               ...             ...             ...  \n",
       "380  location_pairs               USA           215.0           215.0  \n",
       "381  location_pairs               USA           231.0           231.0  \n",
       "382  location_pairs               USA           161.0           161.0  \n",
       "383  location_pairs               USA           219.0           219.0  \n",
       "384  location_pairs               USA           191.0           191.0  \n",
       "\n",
       "[2126 rows x 17 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save csv file\n",
    "df_single_median_depth_q1q3['grouping'] = \"SVI_from\"\n",
    "df_multi_median_depth_q1q3['grouping'] = \"participants_from\"\n",
    "df_par_from_svi_from_median_q1q3['grouping'] = \"location_pairs\"\n",
    "\n",
    "df_median_q1q3 = pd.concat([df_single_median_depth_q1q3, df_multi_median_depth_q1q3, df_par_from_svi_from_median_q1q3])\n",
    "df_median_q1q3.to_csv(\"data/depth/qscores_by_q1q3_median_depth.csv\")\n",
    "df_median_q1q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b2d649",
   "metadata": {},
   "source": [
    "# Calculate mean depths distribution within each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ddc3c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_bins_individual(data):\n",
    "    \"\"\"Find optimal bins for individual distribution\"\"\"\n",
    "    n = len(data)\n",
    "    q75, q25 = np.percentile(data, [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    \n",
    "    if iqr == 0:\n",
    "        return max(5, int(np.ceil(np.log2(n) + 1)))\n",
    "    \n",
    "    h = 2 * iqr / (n**(1/3))\n",
    "    n_bins = int(np.ceil((data.max() - data.min()) / h))\n",
    "    return max(5, min(n_bins, 100))\n",
    "\n",
    "def compute_mean_histogram_individual_bins(df):\n",
    "    \"\"\"\n",
    "    Use optimal bins for each distribution - more accurate per distribution\n",
    "    \"\"\"\n",
    "    # Find individual optimal bins for each distribution\n",
    "    individual_results = []\n",
    "    \n",
    "    for depth_array in df['depth']:\n",
    "        # Find optimal bins for this specific distribution\n",
    "        n_bins = find_optimal_bins_individual(depth_array)\n",
    "        hist, bin_edges = np.histogram(depth_array, bins=n_bins, density=False)\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        \n",
    "        individual_results.append({\n",
    "            'histogram': hist,\n",
    "            'bin_centers': bin_centers,\n",
    "            'bin_edges': bin_edges,\n",
    "            'n_bins': n_bins\n",
    "        })\n",
    "    \n",
    "    # To average these, we need to interpolate to common x-axis\n",
    "    # Use the global range but with higher resolution\n",
    "    all_values = np.concatenate(df['depth'].values)\n",
    "    global_min, global_max = all_values.min(), all_values.max()\n",
    "    \n",
    "    # Create high-resolution common x-axis\n",
    "    common_x = np.linspace(global_min, global_max, 1000)\n",
    "    \n",
    "    # Interpolate each histogram to common x-axis\n",
    "    interpolated_hists = []\n",
    "    for result in individual_results:\n",
    "        f = interpolate.interp1d(\n",
    "            result['bin_centers'], \n",
    "            result['histogram'], \n",
    "            kind='linear',\n",
    "            bounds_error=False,  # Don't raise error for out-of-bounds\n",
    "            fill_value=0.0       # Use 0 for extrapolation\n",
    "        )\n",
    "        interp_hist = f(common_x)\n",
    "        interpolated_hists.append(interp_hist)\n",
    "    \n",
    "    # Average the interpolated histograms\n",
    "    mean_histogram = np.mean(interpolated_hists, axis=0)\n",
    "    \n",
    "    return {\n",
    "        'mean_histogram': mean_histogram,\n",
    "        'bin_centers': common_x,\n",
    "        'individual_results': individual_results,\n",
    "        'approach': 'individual_bins'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484f2002",
   "metadata": {},
   "source": [
    "## single SVI multi participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd78b58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVI_from</th>\n",
       "      <th>quantile</th>\n",
       "      <th>mean_depth_hist</th>\n",
       "      <th>grouping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abuja</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abuja</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Santiago</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Santiago</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SVI_from quantile                                    mean_depth_hist  \\\n",
       "0           Abuja       Q1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1           Abuja       Q3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2             All       Q1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3             All       Q3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4       Amsterdam       Q1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "5       Amsterdam       Q3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "6   San Francisco       Q1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7   San Francisco       Q3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8        Santiago       Q1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9        Santiago       Q3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "10      Singapore       Q1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "11      Singapore       Q3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "    grouping  \n",
       "0   SVI_from  \n",
       "1   SVI_from  \n",
       "2   SVI_from  \n",
       "3   SVI_from  \n",
       "4   SVI_from  \n",
       "5   SVI_from  \n",
       "6   SVI_from  \n",
       "7   SVI_from  \n",
       "8   SVI_from  \n",
       "9   SVI_from  \n",
       "10  SVI_from  \n",
       "11  SVI_from  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute mean hist for each combination of svi_from x quantile\n",
    "single_list = []\n",
    "for city in df_single_depth_q1q3['SVI_from'].unique():\n",
    "    for quantile in df_single_depth_q1q3['quantile'].unique():\n",
    "        df_aux = df_single_depth_q1q3[(df_single_depth_q1q3['SVI_from'] == city) & (df_single_depth_q1q3['quantile'] == quantile)]\n",
    "        df_filtered = df_depth_rel[df_depth_rel['uuid'].isin(df_aux['uuid'])]\n",
    "        mean_histogram_dict = compute_mean_histogram_individual_bins(df_filtered)\n",
    "        single_list.append({'SVI_from': city,\n",
    "                          'quantile': quantile,\n",
    "                          'mean_depth_hist': mean_histogram_dict['mean_histogram']}) \n",
    "single_df = pd.DataFrame(single_list)\n",
    "single_df['grouping'] = \"SVI_from\"\n",
    "single_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87e59da",
   "metadata": {},
   "source": [
    "## multi SVI single participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efad6965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participants_from</th>\n",
       "      <th>quantile</th>\n",
       "      <th>mean_depth_hist</th>\n",
       "      <th>grouping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>participants_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>participants_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chile</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>participants_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chile</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>participants_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>participants_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>participants_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>participants_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>participants_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>participants_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>participants_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>USA</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>participants_from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>USA</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>participants_from</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participants_from quantile  \\\n",
       "0                All       Q1   \n",
       "1                All       Q3   \n",
       "2              Chile       Q1   \n",
       "3              Chile       Q3   \n",
       "4        Netherlands       Q1   \n",
       "5        Netherlands       Q3   \n",
       "6            Nigeria       Q1   \n",
       "7            Nigeria       Q3   \n",
       "8          Singapore       Q1   \n",
       "9          Singapore       Q3   \n",
       "10               USA       Q1   \n",
       "11               USA       Q3   \n",
       "\n",
       "                                      mean_depth_hist           grouping  \n",
       "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  participants_from  \n",
       "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  participants_from  \n",
       "2   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  participants_from  \n",
       "3   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  participants_from  \n",
       "4   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  participants_from  \n",
       "5   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  participants_from  \n",
       "6   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  participants_from  \n",
       "7   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  participants_from  \n",
       "8   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  participants_from  \n",
       "9   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  participants_from  \n",
       "10  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  participants_from  \n",
       "11  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  participants_from  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute mean hist for each combination of svi_from x quantile\n",
    "multi_list = []\n",
    "for city in df_multi_depth_q1q3['participants_from'].unique():\n",
    "    for quantile in df_multi_depth_q1q3['quantile'].unique():\n",
    "        df_aux = df_multi_depth_q1q3[(df_multi_depth_q1q3['participants_from'] == city) & (df_multi_depth_q1q3['quantile'] == quantile)]\n",
    "        df_filtered = df_depth_rel[df_depth_rel['uuid'].isin(df_aux['uuid'])]\n",
    "        mean_histogram_dict = compute_mean_histogram_individual_bins(df_filtered)\n",
    "        multi_list.append({'participants_from': city,\n",
    "                          'quantile': quantile,\n",
    "                          'mean_depth_hist': mean_histogram_dict['mean_histogram']}) \n",
    "multi_df = pd.DataFrame(multi_list)\n",
    "multi_df['grouping'] = \"participants_from\"\n",
    "multi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213c2a44",
   "metadata": {},
   "source": [
    "## location pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74eeb926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participants_from</th>\n",
       "      <th>SVI_from</th>\n",
       "      <th>quantile</th>\n",
       "      <th>mean_depth_hist</th>\n",
       "      <th>grouping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chile</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.5333333333333333, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chile</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chile</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chile</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chile</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chile</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chile</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chile</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chile</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 3.44913690657322, 2.8607635801...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chile</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.357...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.967...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>USA</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>USA</td>\n",
       "      <td>Abuja</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>USA</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>USA</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>USA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>USA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>USA</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>USA</td>\n",
       "      <td>Santiago</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>USA</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.840465687766181, 2.355922948...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>USA</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participants_from       SVI_from quantile  \\\n",
       "0              Chile          Abuja       Q1   \n",
       "1              Chile          Abuja       Q3   \n",
       "2              Chile      Amsterdam       Q1   \n",
       "3              Chile      Amsterdam       Q3   \n",
       "4              Chile  San Francisco       Q1   \n",
       "5              Chile  San Francisco       Q3   \n",
       "6              Chile       Santiago       Q1   \n",
       "7              Chile       Santiago       Q3   \n",
       "8              Chile      Singapore       Q1   \n",
       "9              Chile      Singapore       Q3   \n",
       "10       Netherlands          Abuja       Q1   \n",
       "11       Netherlands          Abuja       Q3   \n",
       "12       Netherlands      Amsterdam       Q1   \n",
       "13       Netherlands      Amsterdam       Q3   \n",
       "14       Netherlands  San Francisco       Q1   \n",
       "15       Netherlands  San Francisco       Q3   \n",
       "16       Netherlands       Santiago       Q1   \n",
       "17       Netherlands       Santiago       Q3   \n",
       "18       Netherlands      Singapore       Q1   \n",
       "19       Netherlands      Singapore       Q3   \n",
       "20           Nigeria          Abuja       Q1   \n",
       "21           Nigeria          Abuja       Q3   \n",
       "22           Nigeria      Amsterdam       Q1   \n",
       "23           Nigeria      Amsterdam       Q3   \n",
       "24           Nigeria  San Francisco       Q1   \n",
       "25           Nigeria  San Francisco       Q3   \n",
       "26           Nigeria       Santiago       Q1   \n",
       "27           Nigeria       Santiago       Q3   \n",
       "28           Nigeria      Singapore       Q1   \n",
       "29           Nigeria      Singapore       Q3   \n",
       "30         Singapore          Abuja       Q1   \n",
       "31         Singapore          Abuja       Q3   \n",
       "32         Singapore      Amsterdam       Q1   \n",
       "33         Singapore      Amsterdam       Q3   \n",
       "34         Singapore  San Francisco       Q1   \n",
       "35         Singapore  San Francisco       Q3   \n",
       "36         Singapore       Santiago       Q1   \n",
       "37         Singapore       Santiago       Q3   \n",
       "38         Singapore      Singapore       Q1   \n",
       "39         Singapore      Singapore       Q3   \n",
       "40               USA          Abuja       Q1   \n",
       "41               USA          Abuja       Q3   \n",
       "42               USA      Amsterdam       Q1   \n",
       "43               USA      Amsterdam       Q3   \n",
       "44               USA  San Francisco       Q1   \n",
       "45               USA  San Francisco       Q3   \n",
       "46               USA       Santiago       Q1   \n",
       "47               USA       Santiago       Q3   \n",
       "48               USA      Singapore       Q1   \n",
       "49               USA      Singapore       Q3   \n",
       "\n",
       "                                      mean_depth_hist        grouping  \n",
       "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.5333333333333333, ...  location_pairs  \n",
       "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "2   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "3   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "4   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "5   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "6   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "7   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "8   [0.0, 0.0, 0.0, 3.44913690657322, 2.8607635801...  location_pairs  \n",
       "9   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "10  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "11  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "12  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "13  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "14  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "15  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.357...  location_pairs  \n",
       "16  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "17  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "18  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.967...  location_pairs  \n",
       "19  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "20  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "21  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "22  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "23  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "24  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "25  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "26  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "27  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "28  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "29  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "30  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "31  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "32  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "33  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "34  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "35  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "36  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "37  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "38  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "39  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "40  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "41  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "42  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "43  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "44  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "45  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "46  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "47  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  \n",
       "48  [0.0, 0.0, 0.0, 2.840465687766181, 2.355922948...  location_pairs  \n",
       "49  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  location_pairs  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute mean hist for each combination of location pair x quantile\n",
    "location_list = []\n",
    "\n",
    "for city_participants in df_par_from_svi_from_q1q3['participants_from'].unique():\n",
    "    for city_svi in df_par_from_svi_from_q1q3['SVI_from'].unique():\n",
    "        for quantile in df_par_from_svi_from_q1q3['quantile'].unique():\n",
    "            df_aux = df_par_from_svi_from_q1q3[(df_par_from_svi_from_q1q3['participants_from'] == city_participants) &\n",
    "                                               (df_par_from_svi_from_q1q3['SVI_from'] == city_svi) & \n",
    "                                               (df_par_from_svi_from_q1q3['quantile'] == quantile)]\n",
    "            df_filtered = df_depth_rel[df_depth_rel['uuid'].isin(df_aux['uuid'])]\n",
    "            mean_histogram_dict = compute_mean_histogram_individual_bins(df_filtered)\n",
    "            location_list.append({\n",
    "                'participants_from': city_participants,\n",
    "                'SVI_from': city_svi,\n",
    "                'quantile': quantile,\n",
    "                'mean_depth_hist': mean_histogram_dict['mean_histogram']}) \n",
    "location_df = pd.DataFrame(location_list)\n",
    "location_df['grouping'] = \"location_pairs\"\n",
    "location_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e2014",
   "metadata": {},
   "source": [
    "## Combine results and save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56c29234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVI_from</th>\n",
       "      <th>quantile</th>\n",
       "      <th>mean_depth_hist</th>\n",
       "      <th>grouping</th>\n",
       "      <th>participants_from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abuja</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abuja</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>SVI_from</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Santiago</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Santiago</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Q1</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.840465687766181, 2.355922948...</td>\n",
       "      <td>location_pairs</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Q3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>location_pairs</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SVI_from quantile                                    mean_depth_hist  \\\n",
       "0           Abuja       Q1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1           Abuja       Q3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2             All       Q1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3             All       Q3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4       Amsterdam       Q1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "..            ...      ...                                                ...   \n",
       "45  San Francisco       Q3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "46       Santiago       Q1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "47       Santiago       Q3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "48      Singapore       Q1  [0.0, 0.0, 0.0, 2.840465687766181, 2.355922948...   \n",
       "49      Singapore       Q3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "          grouping participants_from  \n",
       "0         SVI_from               NaN  \n",
       "1         SVI_from               NaN  \n",
       "2         SVI_from               NaN  \n",
       "3         SVI_from               NaN  \n",
       "4         SVI_from               NaN  \n",
       "..             ...               ...  \n",
       "45  location_pairs               USA  \n",
       "46  location_pairs               USA  \n",
       "47  location_pairs               USA  \n",
       "48  location_pairs               USA  \n",
       "49  location_pairs               USA  \n",
       "\n",
       "[74 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.concat([single_df, multi_df, location_df])\n",
    "results_df['mean_depth_hist'] = results_df['mean_depth_hist'].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)\n",
    "results_df.to_csv(\"data/depth/mean_depth_hist_by_q1q3_qscores.csv\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e5dccb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greenery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
